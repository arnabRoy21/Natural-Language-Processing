{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Machine Translation and Locality Sensitive Hashing (LSH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from utils_arnab import get_en_to_fr_dict, get_word_embedding_matrices, distance_cosine_score, get_indices_to_word_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the word embeddings data for English and French words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the english and french word embedding subset models\n",
    "en_embeddings = pickle.load(open('en_embeddings.p', 'rb'))\n",
    "fr_embeddings = pickle.load(open('fr_embeddings.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the:  [ 0.08007812  0.10498047  0.04980469  0.0534668  -0.06738281]\n",
      "la:  [-0.0061825  -0.00094387 -0.00882648  0.0324623  -0.0218281 ]\n"
     ]
    }
   ],
   "source": [
    "# check the word embeddings upto 5 dimensions\n",
    "print('the: ', en_embeddings['the'][:5])\n",
    "print('la: ', fr_embeddings['la'][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English word embedding dimension: 300\n",
      "French word embedding dimension: 300\n"
     ]
    }
   ],
   "source": [
    "# check the dimensions of English and french word embeddings\n",
    "print('English word embedding dimension:', len(en_embeddings['the']))\n",
    "print('French word embedding dimension:', len(fr_embeddings['la']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the English to French word mapping dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the English to French training dictionary is 5000\n",
      "The length of the English to French test dictionary is 1500\n"
     ]
    }
   ],
   "source": [
    "# loading the english to french dictionaries\n",
    "en_fr_train = get_en_to_fr_dict('en-fr.train.txt')\n",
    "print('The length of the English to French training dictionary is', len(en_fr_train))\n",
    "en_fr_test = get_en_to_fr_dict('en-fr.test.txt')\n",
    "print('The length of the English to French test dictionary is', len(en_fr_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build master english to french mapping\n",
    "keys = list(en_fr_train.keys()) + list(en_fr_test.keys())\n",
    "values = list(en_fr_train.values()) + list(en_fr_test.values())\n",
    "master_en_fr_dict = {key: value for key, value in zip(keys, values)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 items:  [('the', 'la'), ('and', 'et'), ('was', '√©tait'), ('for', 'pour'), ('that', 'cela')]\n",
      "Last 5 items:  [('madonna', 'madonna'), ('worcester', 'worcester'), ('cooperative', 'coop√©ratif'), ('substantially', 'sensiblement'), ('winston', 'winston')]\n"
     ]
    }
   ],
   "source": [
    "# check the master to frech dictionary set\n",
    "print('First 5 items: ',list(master_en_fr_dict.items())[:5])\n",
    "print('Last 5 items: ',list(master_en_fr_dict.items())[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 'la'),\n",
       " ('and', 'et'),\n",
       " ('was', '√©tait'),\n",
       " ('for', 'pour'),\n",
       " ('that', 'cela')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the english to french dictionary\n",
    "list(en_fr_train.items())[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate embedding matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:image width px; font-size:100%; text-align:center;\">\n",
    "<img src='X_to_Y.jpg' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:800px;height:200px;\" /><center>Figure 2 </center></h1></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the word embedding matrices for the english and french words from the train set\n",
    "X_train, Y_train = get_word_embedding_matrices(\n",
    "    en_fr_train, en_embeddings, fr_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02600098, -0.00189209,  0.18554688, -0.05175781,  0.00512695])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the Translation Matrix to translate English words to French words\n",
    "\n",
    "<div style=\"width:image width px; font-size:100%; text-align:center;\"><img src='e_to_f.jpg' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:700px;height:200px;\" /> <center>Figure 2</center> </div>\n",
    "\n",
    "Given English and French Word Embedding Matrices, $ {\\mathbf{X}}\\ and\\ {\\mathbf{Y}} $ -\n",
    "\n",
    "We need to find a matrix $ {\\mathbf{R}} $ that minimizes the following equation. \n",
    "\n",
    "$$\\arg \\min _{\\mathbf{R}}\\| \\mathbf{X R} - \\mathbf{Y}\\|_{F}\\tag{1} $$\n",
    "\n",
    "We will optimize below equation instead of the above equation,\n",
    "$$ \\frac{1}{m} \\|  \\mathbf{X R} - \\mathbf{Y} \\|_{F}^{2}$$\n",
    "\n",
    "where $m$ is the number of samples of $ {\\mathbf{X}} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function to optimize\n",
    "def compute_loss(X, Y, R):\n",
    "    \"\"\"\n",
    "    computes the loss defined as the square of the frobenius norm of matrix [ XR - Y ] divided by the number of rows of X\n",
    "\n",
    "    Params:\n",
    "    ----------\n",
    "    X: numpy array\n",
    "        english embedding matrix\n",
    "    Y: numpy array\n",
    "        french embedding matrix\n",
    "    R: numpy array\n",
    "        transformation matrix\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    loss: float\n",
    "        defined as the square of the frobenius norm of matrix [ XR - Y ] divided by the number of rows of X\n",
    "    \"\"\"\n",
    "\n",
    "    m = X.shape[0]\n",
    "\n",
    "    loss = 1/m * (np.linalg.norm(np.dot(X, R) - Y)**2)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the gradient of loss with respect to transform matrix R\n",
    "\n",
    "* The formula for the gradient of the loss function $ùêø(ùëã,ùëå,ùëÖ)$ is:\n",
    "\n",
    "$$\\frac{d}{dR}ùêø(ùëã,ùëå,ùëÖ)=\\frac{d}{dR}\\Big(\\frac{1}{m}\\| X R -Y\\|_{F}^{2}\\Big) = \\frac{2}{m}X^{T} (X R - Y)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(X, Y, R):\n",
    "    \"\"\"\n",
    "    computes the gradient of the loss function where the loss function is defined as the \n",
    "    square of the frobenius norm of matrix [ XR - Y ] divided by the number of rows of X\n",
    "\n",
    "    Params:\n",
    "    ----------\n",
    "    X: numpy array\n",
    "        english embedding matrix\n",
    "    Y: numpy array\n",
    "        french embedding matrix\n",
    "    R: numpy array\n",
    "        transformation matrix\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    grad: numpy array\n",
    "        gradient of the loss function F-norm ||X R -Y||^2 for given X, Y and R\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[0]\n",
    "\n",
    "    grad = 2/m * np.dot(X.T, (np.dot(X, R) - Y))\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the optimal R with gradient descent algorithm\n",
    "\n",
    "* Update $R$ with the formula:\n",
    "$$R_{\\text{new}}= R_{\\text{old}}-\\alpha g$$\n",
    "\n",
    "where, $g$ is the gradient of the loss with respect to the matrix $R$ and $\\alpha$ is the learning rate, which is a scalar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, Y, train_steps=400, learning_rate=0.0003):\n",
    "    \"\"\"\n",
    "    Computes the optimal transform matrix (R) by minimizing the squared frobenius loss function using gradient descent algorithm\n",
    "\n",
    "    Params:\n",
    "    ----------\n",
    "        X: a numpy matrix of dimension (m,n) where the columns are the English embeddings.\n",
    "        Y: a numpy matrix of dimension (m,n) where the columns correspong to the French embeddings.\n",
    "        train_steps: the number of epochs for the gradient descent algorithm\n",
    "        learning_rate: the learning rate used in the gradient descent update of R\n",
    "    \n",
    "    Returns:\n",
    "    ----------\n",
    "        R: the optimal transform matrix of dimension (n,n) by minimizing F-norm ||X R -Y||^2.\n",
    "    \"\"\"\n",
    "    np.random.seed(200)\n",
    "    \n",
    "    dim = X.shape[1]  # get the embedding dimension\n",
    "\n",
    "    R = np.random.rand(dim, dim)  # initialize the transform matrix\n",
    "\n",
    "    for i in range(train_steps):\n",
    "        if i % 50 == 0:\n",
    "            print(f\"Loss at iteration {i} is: {compute_loss(X, Y, R):.4f}\")\n",
    "        grad = compute_gradient(X, Y, R)\n",
    "        # update the transform matrix\n",
    "        R = R - learning_rate * grad\n",
    "    return R\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at iteration 0 is: 966.4205\n",
      "Loss at iteration 50 is: 23.3787\n",
      "Loss at iteration 100 is: 3.7070\n",
      "Loss at iteration 150 is: 1.2678\n",
      "Loss at iteration 200 is: 0.7658\n",
      "Loss at iteration 250 is: 0.6313\n",
      "Loss at iteration 300 is: 0.5892\n",
      "Loss at iteration 350 is: 0.5744\n",
      "Loss at iteration 400 is: 0.5688\n",
      "Loss at iteration 450 is: 0.5665\n",
      "Loss at iteration 500 is: 0.5655\n",
      "Loss at iteration 550 is: 0.5651\n",
      "Loss at iteration 600 is: 0.5649\n",
      "Loss at iteration 650 is: 0.5648\n",
      "Loss at iteration 700 is: 0.5647\n",
      "Loss at iteration 750 is: 0.5647\n",
      "Loss at iteration 800 is: 0.5647\n",
      "Loss at iteration 850 is: 0.5647\n",
      "Loss at iteration 900 is: 0.5647\n",
      "Loss at iteration 950 is: 0.5647\n"
     ]
    }
   ],
   "source": [
    "R_train = gradient_descent(X_train, Y_train, train_steps=1000, learning_rate=0.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Translation\n",
    "\n",
    "Use a KNN algorithm to map the approximated embedding vector $\\hat{Y}$ = $XR \\xrightarrow{\\text{to an actual vector in}}$  $Y$ vector space \n",
    "\n",
    "We will use below metric as distance measure for the KNN - \n",
    "$$d_{\\text{cos}}(u,v)=1-\\cos(u,v)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_neighbor(v, candidates, k=1, metric=distance_cosine_score):\n",
    "    \"\"\"\n",
    "    compute the nearest neighbor of the approximated french word vector v = ( X * R ) in the acutal Y vector space\n",
    "\n",
    "    Params:\n",
    "    ----------\n",
    "    v: numpy array\n",
    "        the approximated french word row vector.\n",
    "    candidates: numpy array\n",
    "        a list of candidate vectors in Y space from which to search the nearest neighbors with respect to v.\n",
    "    k: int\n",
    "        number representing the top k nearest neighbors of v to search for.\n",
    "    metric: function\n",
    "        callable function used as a distance metric, default is cosine similarity\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    knn_idx: numpy array\n",
    "        list of indices of k nearest neighbors found in Y vector space with respect to v.\n",
    "    \"\"\"\n",
    "\n",
    "    distance_scores = []\n",
    "    for vec in candidates:\n",
    "        score = metric(v, vec)\n",
    "        distance_scores.append(score)\n",
    "    \n",
    "    knn_idx = np.argsort(distance_scores)[:k]\n",
    "\n",
    "    return knn_idx        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 1],\n",
       "       [1, 0, 5],\n",
       "       [9, 9, 9]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test knn\n",
    "v = np.array([1, 0, 1])\n",
    "candidates = np.array([[1, 0, 5], [-2, 5, 3], [2, 0, 1], [6, -9, 5], [9, 9, 9]])\n",
    "candidates[nearest_neighbor(v, candidates, 3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Accuracy\n",
    "$$\\text{accuracy}=\\frac{\\#(\\text{correct predictions})}{\\#(\\text{total predictions})}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_vocabulary(X, Y, R):\n",
    "    \"\"\"\n",
    "    calculates the accuracy of translations from X to Y by R\n",
    "\n",
    "    Params:\n",
    "    ----------\n",
    "    X: numpy array\n",
    "        english embedding matrix\n",
    "    Y: numpy array\n",
    "        french embedding matrix\n",
    "    R: numpy array\n",
    "        transformation matrix\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    acc: float\n",
    "        accuracy is calculated by checking if the indices match b/w XR and Y. \n",
    "        The result is stored in an array and averaged to produce the accuracy score\n",
    "    \"\"\"\n",
    "    acc = 0\n",
    "    matched_idx = []\n",
    "    for idx, vec in enumerate(X):\n",
    "        y_pred = np.dot(vec, R)\n",
    "        if idx == nearest_neighbor(y_pred, Y, k=1).item():\n",
    "            matched_idx.append(idx)\n",
    "            acc += 1\n",
    "    acc = acc / X.shape[0]\n",
    "\n",
    "    return acc, matched_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Accuracy on 1000 Samples of Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Train Data: 0.59\n"
     ]
    }
   ],
   "source": [
    "acc_train, matched_idx_train = test_vocabulary(X_train[:1000,:], Y_train[:1000,:], R_train)\n",
    "print(f'Accuracy on Train Data: {acc_train:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 8, 10, 14]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_idx_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Accuracy on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, Y_val = get_word_embedding_matrices(en_fr_test, en_embeddings, fr_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Data: 0.56\n"
     ]
    }
   ],
   "source": [
    "acc_test, matched_idx_test = test_vocabulary(X_val, Y_val, R_train)\n",
    "print(f'Accuracy on Test Data: {acc_test:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 6, 8, 9]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_idx_test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the translation predictions made by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create indices to word dictionary mapping from the english to french master database map\n",
    "en_iw, fr_iw = get_indices_to_word_dict(master_en_fr_dict, en_embeddings, fr_embeddings)\n",
    "# en_iw, fr_iw = get_indices_to_word_dict(en_fr_test, en_embeddings, fr_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'the'),\n",
       " (1, 'was'),\n",
       " (2, 'for'),\n",
       " (3, 'that'),\n",
       " (4, 'with'),\n",
       " (5, 'from'),\n",
       " (6, 'this')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(en_iw.items())[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'la'),\n",
       " (1, '√©tait'),\n",
       " (2, 'pour'),\n",
       " (3, 'cela'),\n",
       " (4, 'avec'),\n",
       " (5, 'depuis'),\n",
       " (6, 'ce')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(fr_iw.items())[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_word(en_word):\n",
    "    \"\"\"\n",
    "    Translates the given english word as parameter to a Frech word.\n",
    "\n",
    "    Params:\n",
    "    ----------\n",
    "    en_word: str\n",
    "        English word that would be translated to French word.\n",
    "    \n",
    "    Returns:\n",
    "    ----------\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    x = en_embeddings[en_word]\n",
    "    y_pred = np.dot(x, R_train)       # approximation of en_word to fr_word\n",
    "    Y = np.vstack((Y_train, Y_val))     # build the complete french embedding vector using both train and test data set as candidates\n",
    "    for idx in nearest_neighbor(y_pred, Y, k=1):\n",
    "        print(en_word, \" --> \",fr_iw[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "circular  -->  circulaires\n",
      "decorated  -->  d√©cor√©\n",
      "beautiful  -->  beaut√©\n",
      "hood  -->  voiture\n",
      "bicycle  -->  v√©lo\n"
     ]
    }
   ],
   "source": [
    "translate_word('circular')\n",
    "translate_word('decorated')\n",
    "translate_word('beautiful')\n",
    "translate_word('hood')\n",
    "translate_word('bicycle')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be observed that translations are sometimes errorneous given the accuracy of the model. Using a larger vocabulary rather than a subset and using a larger training data would improve accuracy of translations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ed98f0601b831bcc7b83204b240d5de8690f3d4c7ae43c4dad5e24aa4ea3791d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
